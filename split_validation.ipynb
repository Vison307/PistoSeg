{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    fontsize=14\n",
    "    n = len(images)\n",
    "    fig, axarr = plt.subplots(nrows=1, ncols=n, figsize=(8, 8))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            if image.ndim == 3: image = image.permute(1, 2, 0)\n",
    "            if image.is_cuda: image = image.detach().cpu().numpy()\n",
    "        if 'mask' in name: \n",
    "            palette = [0, 64, 128, 64, 128, 0, 243, 152, 0, 255, 255, 255] + [0] * 252 * 3\n",
    "            image = Image.fromarray(np.uint8(image), mode='P')\n",
    "            image.putpalette(palette)\n",
    "            axarr[i].imshow(image)\n",
    "            axarr[i].set_title(name, fontsize=fontsize)\n",
    "        else:\n",
    "            axarr[i].imshow(image)\n",
    "            axarr[i].set_title(name, fontsize=fontsize)\n",
    "            \n",
    "    for ax in axarr.ravel():\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_cut_patches(im, im_size, stride):\n",
    "    \"\"\"\n",
    "    function for crop the image to subpatches, will include corner cases\n",
    "    the return position (x,y) is the up left corner of the image\n",
    "    \n",
    "    Args:\n",
    "        im (np.ndarray): the image for cropping\n",
    "        im_size (int): the sub-image size.\n",
    "        stride (int): the pixels between two sub-images.\n",
    "    \n",
    "    Returns:\n",
    "        (list, list): list of image reference and list of its corresponding positions\n",
    "    \"\"\"\n",
    "    im_list = []\n",
    "    position_list = []\n",
    "\n",
    "    h, w, _ = im.shape\n",
    "    if h < im_size:\n",
    "        h_ = np.array([0])\n",
    "    else:\n",
    "        h_ = np.arange(0, h - im_size + 1, stride)\n",
    "        if h % stride != 0:\n",
    "            h_ = np.append(h_, h-im_size)\n",
    "\n",
    "    if w < im_size:\n",
    "        w_ = np.array([0])\n",
    "    else:\n",
    "        w_ = np.arange(0, w - im_size + 1, stride)\n",
    "        if w % stride != 0:\n",
    "            w_ = np.append(w_, w - im_size)\n",
    "\n",
    "    for i in h_:\n",
    "        for j in w_:   \t\n",
    "            temp = np.uint8(im[i:i+im_size,j:j+im_size,:])\n",
    "            im_list.append(temp)\n",
    "            position_list.append((i,j))\n",
    "    return im_list, position_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiscale_online_crop(im, im_size, stride, scales):\n",
    "    \"\"\"\n",
    "    First resize the image to different scales, then crop according to `im_size`\n",
    "\n",
    "    Returns:\n",
    "        scale_im_list: the image list\n",
    "        [\n",
    "            im_list_of_scale_1: [im_1, im_2, ...],\n",
    "            im_list_of_scale_2: [im_1, im_2, ...],\n",
    "            ...,\n",
    "            im_list_of_scale_n: [im_1, im_2, ...],\n",
    "        ]\n",
    "        scale_position_list: the images position\n",
    "        [\n",
    "            pos_list_of_scale_1: [(x1, y1), (x2, y2), ...],\n",
    "            pos_list_of_scale_2: [(x1, y1), (x2, y2), ...],\n",
    "            ...,\n",
    "            pos_list_of_scale_n: [(x1, y1), (x2, y2), ...],\n",
    "        ]\n",
    "    \n",
    "    \"\"\"\n",
    "    # ----> Get the PIL.Image object\n",
    "    im = Image.fromarray(im)\n",
    "    w, h = im.size\n",
    "\n",
    "    scale_im_list = []\n",
    "    scale_position_list = []\n",
    "\n",
    "    # ----> For each scale\n",
    "    for scale in scales:\n",
    "        scaled_im = np.asarray(im.resize((int(w * scale), int(h * scale))))\n",
    "        \n",
    "        im_list, position_list = online_cut_patches(scaled_im, im_size, stride) # im_size: 224, stride: 75\n",
    "        scale_im_list.append(im_list)\n",
    "        scale_position_list.append(position_list)\n",
    "\n",
    "    return scale_im_list, scale_position_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_image_dir = Path('data/WSSS4LUAD/2.validation/img')\n",
    "validation_image_paths = sorted(list(validation_image_dir.glob('*.png')))\n",
    "validation_mask_dir = Path('data/WSSS4LUAD/2.validation/mask')\n",
    "validation_mask_paths = [validation_mask_dir / f'{p.stem}.png' for p in validation_image_paths]\n",
    "len(validation_mask_paths) # 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path, mask_path in tqdm(zip(validation_image_paths, validation_mask_paths)):\n",
    "    image_name = image_path.stem\n",
    "    image_data = np.array(Image.open(image_path))\n",
    "\n",
    "    im_size = 224\n",
    "    stride = 56\n",
    "    scales = [1]\n",
    "    scale_img_list, scale_position_list = multiscale_online_crop(image_data, im_size, stride, scales)\n",
    "    \n",
    "    image_patch_dir = Path(f'data/WSSS4LUAD/2.validation/patches_{im_size}_{stride}/img')\n",
    "    image_patch_dir.mkdir(parents=True, exist_ok=True)\n",
    "    mask_patch_dir = Path(f'data/WSSS4LUAD/2.validation/patches_{im_size}_{stride}/mask')\n",
    "    mask_patch_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for scale, im_list, position_list in zip(scales, scale_img_list, scale_position_list):\n",
    "        w, h = Image.open(mask_path).size\n",
    "        mask_data = np.array(Image.open(mask_path).resize((int(w*scale), int(h*scale)), resample=Image.BILINEAR))\n",
    "\n",
    "        for image_patch, position in zip(im_list, position_list):\n",
    "            i, j = position\n",
    "            mask_patch = np.uint8(mask_data[i:i+im_size, j:j+im_size])\n",
    "\n",
    "            patch_label = [0, 0, 0]\n",
    "            for cat in range(3):\n",
    "                if cat in mask_patch:\n",
    "                    patch_label[cat] = 1\n",
    "\n",
    "            image_patch = Image.fromarray(np.uint8(image_patch))\n",
    "            mask_patch = Image.fromarray(np.uint8(mask_patch), mode='P')\n",
    "            palette = [0, 64, 128, 64, 128, 0, 243, 152, 0, 255, 255, 255] + [0] * 252 * 3\n",
    "            mask_patch = Image.fromarray(np.uint8(mask_patch), mode='P')\n",
    "            mask_patch.putpalette(palette)\n",
    "\n",
    "            image_patch.save(image_patch_dir / f'{image_name}_{scale}_{i}_{j}-{patch_label}.png')\n",
    "            mask_patch.save(mask_patch_dir / f'{image_name}_{scale}_{i}_{j}-{patch_label}.png')\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path, mask_path in tqdm(zip(validation_image_paths, validation_mask_paths)):\n",
    "    image_name = image_path.stem\n",
    "    image_data = np.array(Image.open(image_path))\n",
    "\n",
    "    im_size = 224\n",
    "    stride = 112\n",
    "    scales = [1, 1.25, 1.5, 1.75, 2]\n",
    "    scale_img_list, scale_position_list = multiscale_online_crop(image_data, im_size, stride, scales)\n",
    "    \n",
    "    image_patch_dir = Path(f'data/WSSS4LUAD/2.validation/patches_{im_size}_{stride}/img')\n",
    "    image_patch_dir.mkdir(parents=True, exist_ok=True)\n",
    "    mask_patch_dir = Path(f'data/WSSS4LUAD/2.validation/patches_{im_size}_{stride}/mask')\n",
    "    mask_patch_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for scale, im_list, position_list in zip(scales, scale_img_list, scale_position_list):\n",
    "        w, h = Image.open(mask_path).size\n",
    "        mask_data = np.array(Image.open(mask_path).resize((int(w*scale), int(h*scale)), resample=Image.BILINEAR))\n",
    "\n",
    "        for image_patch, position in zip(im_list, position_list):\n",
    "            i, j = position\n",
    "            mask_patch = np.uint8(mask_data[i:i+im_size, j:j+im_size])\n",
    "\n",
    "            patch_label = [0, 0, 0]\n",
    "            for cat in range(3):\n",
    "                if cat in mask_patch:\n",
    "                    patch_label[cat] = 1\n",
    "\n",
    "            image_patch = Image.fromarray(np.uint8(image_patch))\n",
    "            mask_patch = Image.fromarray(np.uint8(mask_patch), mode='P')\n",
    "            palette = [0, 64, 128, 64, 128, 0, 243, 152, 0, 255, 255, 255] + [0] * 252 * 3\n",
    "            mask_patch = Image.fromarray(np.uint8(mask_patch), mode='P')\n",
    "            mask_patch.putpalette(palette)\n",
    "\n",
    "            image_patch.save(image_patch_dir / f'{image_name}_{scale}_{i}_{j}-{patch_label}.png')\n",
    "            mask_patch.save(mask_patch_dir / f'{image_name}_{scale}_{i}_{j}-{patch_label}.png')\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_dir = Path('data/WSSS4LUAD/3.testing/img')\n",
    "test_image_paths = sorted(list(test_image_dir.glob('*.png')))\n",
    "test_mask_dir = Path('data/WSSS4LUAD/3.testing/mask')\n",
    "test_mask_paths = [test_mask_dir / f'{p.stem}.png' for p in test_image_paths]\n",
    "len(test_mask_paths) # 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path, mask_path in tqdm(zip(test_image_paths, test_mask_paths)):\n",
    "    image_name = image_path.stem\n",
    "    image_data = np.array(Image.open(image_path))\n",
    "    # print(f'H: {image_data.shape[0]}, W: {image_data.shape[1]}')\n",
    "\n",
    "    im_size = 224\n",
    "    stride = 112\n",
    "    scales = [1, 1.25, 1.5, 1.75, 2]\n",
    "    scale_img_list, scale_position_list = multiscale_online_crop(image_data, im_size, stride, scales)\n",
    "    \n",
    "    image_patch_dir = Path(f'data/WSSS4LUAD/3.testing/patches_{im_size}_{stride}/img')\n",
    "    image_patch_dir.mkdir(parents=True, exist_ok=True)\n",
    "    mask_patch_dir = Path(f'data/WSSS4LUAD/3.testing/patches_{im_size}_{stride}/mask')\n",
    "    mask_patch_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for scale, im_list, position_list in zip(scales, scale_img_list, scale_position_list):\n",
    "        w, h = Image.open(mask_path).size\n",
    "        mask_data = np.array(Image.open(mask_path).resize((int(w*scale), int(h*scale)), resample=Image.BILINEAR))\n",
    "\n",
    "        for image_patch, position in zip(im_list, position_list):\n",
    "            i, j = position\n",
    "            mask_patch = np.uint8(mask_data[i:i+im_size, j:j+im_size])\n",
    "\n",
    "            patch_label = [0, 0, 0]\n",
    "            for cat in range(3):\n",
    "                if cat in mask_patch:\n",
    "                    patch_label[cat] = 1\n",
    "\n",
    "            image_patch = Image.fromarray(np.uint8(image_patch))\n",
    "            mask_patch = Image.fromarray(np.uint8(mask_patch), mode='P')\n",
    "            palette = [0, 64, 128, 64, 128, 0, 243, 152, 0, 255, 255, 255] + [0] * 252 * 3\n",
    "            mask_patch = Image.fromarray(np.uint8(mask_patch), mode='P')\n",
    "            mask_patch.putpalette(palette)\n",
    "\n",
    "            image_patch.save(image_patch_dir / f'{image_name}_{scale}_{i}_{j}-{patch_label}.png')\n",
    "            mask_patch.save(mask_patch_dir / f'{image_name}_{scale}_{i}_{j}-{patch_label}.png')\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('wsss4luad')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "153d7fbbbee1d273a0ca8d1411d96d9bc2f994be0d513b7341e48284653310bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
